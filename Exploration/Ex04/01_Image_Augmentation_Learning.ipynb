{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d78ff-3db8-4ab2-9f4b-46589d38e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow\n",
    "!wget https://d3s0tskafalll9.cloudfront.net/media/documents/mycat.jpg\n",
    "!mv mycat.jpg ~/work/data_augmentation/images\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sample_img_path = os.getenv('HOME')+'/work/data_augmentation/images/mycat.jpg'\n",
    "sample_img_path\n",
    "\n",
    "image = Image.open(sample_img_path).resize((500, 400)) # 이미지에 따라 숫자를 바꾸어 보세요.\n",
    "image_tensor = F.to_tensor(image) # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "image\n",
    "\n",
    "flip_lr_tensor = F.hflip(image_tensor)\n",
    "flip_ud_tensor = F.vflip(image_tensor)\n",
    "flip_lr_image = F.to_pil_image(flip_lr_tensor)\n",
    "flip_ud_image = F.to_pil_image(flip_ud_tensor)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Original image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('flip_left_right')\n",
    "plt.imshow(flip_lr_image)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('flip_up_down')\n",
    "plt.imshow(flip_ud_image)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 16))\n",
    "random_flip_lr = transforms.RandomHorizontalFlip(p=0.5)\n",
    "random_flip_ud = transforms.RandomVerticalFlip(p=0.5)\n",
    "\n",
    "row = 4\n",
    "for i in range(row):\n",
    "    flip_lr_tensor = random_flip_lr(image_tensor)\n",
    "    flip_ud_tensor = random_flip_ud(image_tensor)\n",
    "    flip_lr_image = F.to_pil_image(flip_lr_tensor)\n",
    "    flip_ud_image = F.to_pil_image(flip_ud_tensor)\n",
    "\n",
    "    plt.subplot(4,3,i*3+1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(4,3,i*3+2)\n",
    "    plt.title('flip_left_right')\n",
    "    plt.imshow(flip_lr_image)\n",
    "\n",
    "    plt.subplot(4,3,i*3+3)\n",
    "    plt.title('flip_up_down')\n",
    "    plt.imshow(flip_ud_image)\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "\n",
    "central_fractions = [1.0, 0.75, 0.5, 0.25, 0.1]\n",
    "col = len(central_fractions)\n",
    "for i, frac in enumerate(central_fractions):\n",
    "    crop_size = (int(image_tensor.shape[1] * frac), int(image_tensor.shape[2] * frac))\n",
    "    cropped_tensor = F.center_crop(image_tensor, crop_size)\n",
    "    cropped_img = F.to_pil_image(cropped_tensor)\n",
    "\n",
    "    plt.subplot(1,col+1,i+1)\n",
    "    plt.title(f'Center crop: {frac}')\n",
    "    plt.imshow(cropped_img)\n",
    "\n",
    "def random_central_crop(image_tensor, range=(0, 1)):\n",
    "    # range 범위에서 무작위로 잘라낼 비율을 선택합니다\n",
    "    central_fraction = torch.rand(1).item() * (range[1] - range[0]) + range[0]\n",
    "    crop_size = (int(image_tensor.shape[1] * central_fraction), int(image_tensor.shape[2] * central_fraction))\n",
    "    cropped_tensor = F.center_crop(image_tensor, crop_size)\n",
    "    return cropped_tensor\n",
    "print('=3')\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "\n",
    "col = 5\n",
    "for i in range(col):\n",
    "    cropped_tensor = random_central_crop(image_tensor)\n",
    "    cropped_img = F.to_pil_image(cropped_tensor)\n",
    "\n",
    "    plt.subplot(1,col+1,i+1)\n",
    "    plt.imshow(cropped_img)\n",
    "\n",
    "# apply random_crop on cat image\n",
    "plt.figure(figsize=(12, 15))\n",
    "random_crop = transforms.RandomCrop(size=(200,200))\n",
    "\n",
    "random_crop_tensor = random_crop(image_tensor)\n",
    "random_crop_image = F.to_pil_image(random_crop_tensor)\n",
    "\n",
    "plt.imshow(random_crop_image)\n",
    "plt.show()\n",
    "\n",
    "# display 5 random cropped images\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "random_crop = transforms.RandomCrop(size=(200,200))\n",
    "\n",
    "for i in range(5):\n",
    "  random_crop_tensor = random_crop(image_tensor)\n",
    "  random_crop_image = F.to_pil_image(random_crop_tensor)\n",
    "  plt.subplot(1, 5, i + 1) # hint : plt.subplot()\n",
    "  plt.imshow(random_crop_image)\n",
    "\n",
    "# apply random_brightness on cat image\n",
    "plt.figure(figsize=(12, 15))\n",
    "brightness_transform = transforms.ColorJitter(brightness=0.5)\n",
    "\n",
    "random_bright_tensor = brightness_transform(image_tensor)\n",
    "random_bright_image = F.to_pil_image(random_bright_tensor)\n",
    "\n",
    "plt.imshow(random_bright_image)\n",
    "plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# display 5 random brightness images\n",
    "\n",
    "plt.figure(figsize=(12, 15))\n",
    "brightness_transform = transforms.ColorJitter(brightness=0.5)\n",
    "\n",
    "col = 5\n",
    "for i in range(5):\n",
    "    random_bright_tensor = brightness_transform(image_tensor)\n",
    "    random_bright_image = F.to_pil_image(random_bright_tensor)\n",
    "\n",
    "    plt.subplot(1,col,i+1)\n",
    "    plt.imshow(random_bright_image)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ef644-3b95-41c3-8a17-8fe8b5ed0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U albumentations\n",
    "\n",
    "import numpy as np\n",
    "image = Image.open(sample_img_path).resize((400, 300)) # 이미지에 따라 숫자를 바꾸어 보세요.\n",
    "image_arr = np.array(image)\n",
    "image_arr.shape\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "print(\"슝\")\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "for i in range(10):\n",
    "    transform = A.Compose([\n",
    "        A.Affine(rotate=(-45, 45),scale=(0.5,0.9),p=0.5)\n",
    "    ])\n",
    "    transformed = transform(image=image_arr)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow((transformed['image']))\n",
    "    plt.show()\n",
    "\n",
    "for i in range(10):\n",
    "    transform = A.Compose(\n",
    "        [A.RandomCrop(width=256, height=256)]\n",
    "    )\n",
    "    transformed = transform(image=image_arr)\n",
    "    visualize(transformed['image'])\n",
    "\n",
    "transform = A.Compose(\n",
    "    [A.MedianBlur(blur_limit=7, p=0.5)]\n",
    ")\n",
    "transformed = transform(image=image_arr)\n",
    "visualize(transformed['image'])\n",
    "\n",
    "transform = A.Compose(\n",
    "    [A.ToGray(p=1),\n",
    "    A.MultiplicativeNoise(multiplier=[0.5, 1.5], elementwise=True, per_channel=True, p=1)]\n",
    ")\n",
    "transformed = transform(image=image_arr)\n",
    "visualize(transformed['image'])\n",
    "\n",
    "# Use various techniques and functions in albumentations library. show 100 images.\n",
    "\n",
    "def transform_data(img_arr):\n",
    "    transform = A.Compose(\n",
    "        [\n",
    "         A.ToGray(p=1), # hint : A.ToGray()\n",
    "         A.MultiplicativeNoise(multiplier=[0.5, 1.5], elementwise=True, per_channel=True, p=1), # hint : A.MultiplicativeNoise()\n",
    "         A.RandomCrop(width=256, height=256, p=1) # hint : A.RandomCrop()\n",
    "        ]\n",
    "    )\n",
    "    t_image = transform(image=img_arr)\n",
    "    t_image = t_image['image']\n",
    "    return t_image\n",
    "\n",
    "plt.figure(figsize=(18,20))\n",
    "for i in range(100):\n",
    "    image = transform_data(image_arr)\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
