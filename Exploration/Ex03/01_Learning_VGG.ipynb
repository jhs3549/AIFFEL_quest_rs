{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903c64e2-a6e3-4759-893e-2637cf95eb4c",
   "metadata": {},
   "source": [
    "# 1. CIFAR10 데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ceac8-c971-4632-9858-b6cc58ed3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터셋을 로드하고 기본 정보를 확인해 보세요.\n",
    "image, label = trainset[0]\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Number of classes: {len(trainset.classes)}\")\n",
    "\n",
    "# 데이터의 개수도 확인해 봅시다.\n",
    "train_size = torch.tensor(len(trainset))\n",
    "test_size = torch.tensor(len(testset))\n",
    "\n",
    "print(f\"Train dataset size: {train_size} (Shape: {train_size.shape})\")\n",
    "print(f\"Test dataset size: {test_size} (Shape: {test_size.shape})\")\n",
    "\n",
    "# 이미지의 표현이 0과 1 사이로 들어오도록 정규화 \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # uint8 → float32 변환 + 0~1 정규화\n",
    "])\n",
    "\n",
    "num_classes = len(trainset.classes)\n",
    "print(num_classes)\n",
    "class_names = trainset.classes\n",
    "print(class_names)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "def show_multiple_images(dataset, n_images=9):\n",
    "    dataiter = iter(dataset)\n",
    "    images, labels = next(dataiter)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axes[i]\n",
    "        img = imshow(images[i])\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Label: {trainset.classes[labels[i]]}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 학습 데이터셋에서 9개의 이미지를 시각화합니다.\n",
    "show_multiple_images(trainloader)\n",
    "# 테스트 데이터셋에서 9개의 이미지를 시각화합니다.\n",
    "show_multiple_images(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c5a56-9d22-4579-888e-19c20d47b5fa",
   "metadata": {},
   "source": [
    "# 2. VGG 기본블록 구성하기 (Conv + MaxPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83794041-fc2d-4863-8f68-33f0345eaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building VGG Block\n",
    "def build_vgg_block(input_layer, num_cnn=3, channel=64, block_num=1):\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "\n",
    "    layers = []\n",
    "    \n",
    "    # CNN 레이어\n",
    "    in_channels = x.size(1)\n",
    "    for cnn_num in range(num_cnn):\n",
    "        layers.append(\n",
    "                        nn.Conv2d(\n",
    "                                    in_channels=in_channels,\n",
    "                                    out_channels=channel,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=1,\n",
    "                                    padding=1,\n",
    "                                )\n",
    "                    )\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        in_channels = channel\n",
    "\n",
    "    # Max Pooling 레이어\n",
    "    layers.append(\n",
    "                    nn.MaxPool2d(\n",
    "                                    kernel_size=2,\n",
    "                                    stride=2\n",
    "                                )\n",
    "                )\n",
    "\n",
    "    # Sequential으로 레이어 묶기\n",
    "    block = nn.Sequential(*layers) # layers 리스트의 모든 요소를 언팩하여 Sequential에 전달, 반환값은 nn.Sequential 객체. nn.Sequential은 클래스임.\n",
    "    return block\n",
    "\n",
    "class VGGNet(nn.Module): # VGGNet은 nn.Module을 상속받음(파이토치 신경망 모델의 모든 공통 기능을 물려받겠다는 의미)\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__() # 부모클래스의 생성자 호출 (= nn.Module.__init__(self))\n",
    "\n",
    "        # VGG 블록 생성\n",
    "        self.vgg_block = build_vgg_block(torch.zeros(1, 3, 32, 32))\n",
    "    def forward(self, x):\n",
    "        return self.vgg_block(x) # 입력 x를 VGG 블록에 통과시켜 출력 반환\n",
    "\n",
    "# 블록 1개짜리 model 생성\n",
    "model = VGGNet()\n",
    "print(model)\n",
    "\n",
    "dummy_input = torch.zeros(1, 3, 32, 32)\n",
    "output = model(dummy_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce30937",
   "metadata": {},
   "source": [
    "# 3. VGG 모델을 생성하는 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 모델 자체를 생성하는 클래스입니다.\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_cnn_list=[2, 2, 3, 3, 3], channel_list=[64, 128, 256, 512, 512], num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        assert len(num_cnn_list) == len(channel_list), \"num_cnn_list와 channel_list의 길이가 일치해야 합니다.\"\n",
    "\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "\n",
    "        for num_cnn, out_channels in zip(num_cnn_list, channel_list):\n",
    "            layers.append(self._make_vgg_block(in_channels, out_channels, num_cnn))\n",
    "            in_channels = out_channels  # 다음 블록의 입력 채널을 설정\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_vgg_block(self, in_channels, out_channels, num_cnn):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.ReLU(True)]\n",
    "        for _ in range(num_cnn - 1):\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU(True))\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))  # Max Pooling 추가\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23041625",
   "metadata": {},
   "source": [
    "# 4. VGG-16, VGG-19 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본값을 그대로 사용해서 VGG 모델을 만들면 VGG-16이 됩니다.\n",
    "vgg_16 = VGG()\n",
    "print(vgg_16)\n",
    "\n",
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "vgg_19 = VGG(num_cnn_list=[2, 2, 4, 4, 4], channel_list=[64, 128, 256, 512, 512])\n",
    "summary(vgg_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85758e8",
   "metadata": {},
   "source": [
    "# 5. VGG-16 vs VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 15\n",
    "\n",
    "# CIFAR-10 데이터셋에 대해 Normalize와 Tensor 변환을 적용하는 코드\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # VGG-16 표준 정규화\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a36a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = time.time()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_16 = torchvision.models.vgg16(pretrained=True)\n",
    "vgg_16.to(device)\n",
    "\n",
    "for param in vgg_16.parameters():\n",
    "    param.requires_grad = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg_16.parameters(), lr=0.001, momentum=0.9, weight_Decay=1e-4)\n",
    "\n",
    "vgg_16_train_losses = []\n",
    "vgg_16_val_accuracy = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    vgg_16.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg_16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / i + 1:.3f}\")\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    vgg_16_train_losses.append(train_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    vgg_16.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vgg_16(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    vgg_16_val_accuracy.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(time.time() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = time.time()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_19 = torchvision.models.vgg19(pretrained=True)\n",
    "vgg_19.to(device)\n",
    "\n",
    "for param in vgg_19.parameters():\n",
    "    param.requires_grad = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg_19.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "vgg_19_train_losses = []\n",
    "vgg_19_val_accuracy = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    vgg_19.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg_19(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / i + 1:.3f}\")\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    vgg_19_train_losses.append(train_loss)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1}: Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    vgg_19.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vgg_19(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    vgg_19_val_accuracy.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(time.time() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12539eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(vgg_16_train_losses, 'r', label=\"VGG-16 Training Loss\")\n",
    "plt.plot(vgg_19_train_losses, 'b', label=\"VGG-19 Training Loss\")\n",
    "\n",
    "plt.title('Model Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2589ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_16_val_accuracy, 'r', label=\"VGG-16 Validation Accuracy\")\n",
    "plt.plot(vgg_19_val_accuracy, 'b', label=\"VGG-19 Validation Accuracy\")\n",
    "\n",
    "plt.title('Model Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
